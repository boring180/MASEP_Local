{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "random.seed(time.time())\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import utils.frame_slicing as frame_slicing\n",
    "import utils.frame_concatent as frame_concatent\n",
    "\n",
    "number_of_squares_x = 11\n",
    "number_of_internal_corners_x = number_of_squares_x - 1\n",
    "number_of_squares_y = 8\n",
    "number_of_internal_corners_y = number_of_squares_y - 1\n",
    "square_size = 0.023 # in meters\n",
    "cameras = ['cam2', 'cam3', 'wide', 'cam0', 'cam1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [2. 0. 0.]\n",
      " [3. 0. 0.]\n",
      " [4. 0. 0.]\n",
      " [5. 0. 0.]\n",
      " [6. 0. 0.]\n",
      " [7. 0. 0.]\n",
      " [8. 0. 0.]\n",
      " [9. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [2. 1. 0.]\n",
      " [3. 1. 0.]\n",
      " [4. 1. 0.]\n",
      " [5. 1. 0.]\n",
      " [6. 1. 0.]\n",
      " [7. 1. 0.]\n",
      " [8. 1. 0.]\n",
      " [9. 1. 0.]\n",
      " [0. 2. 0.]\n",
      " [1. 2. 0.]\n",
      " [2. 2. 0.]\n",
      " [3. 2. 0.]\n",
      " [4. 2. 0.]\n",
      " [5. 2. 0.]\n",
      " [6. 2. 0.]\n",
      " [7. 2. 0.]\n",
      " [8. 2. 0.]\n",
      " [9. 2. 0.]\n",
      " [0. 3. 0.]\n",
      " [1. 3. 0.]\n",
      " [2. 3. 0.]\n",
      " [3. 3. 0.]\n",
      " [4. 3. 0.]\n",
      " [5. 3. 0.]\n",
      " [6. 3. 0.]\n",
      " [7. 3. 0.]\n",
      " [8. 3. 0.]\n",
      " [9. 3. 0.]\n",
      " [0. 4. 0.]\n",
      " [1. 4. 0.]\n",
      " [2. 4. 0.]\n",
      " [3. 4. 0.]\n",
      " [4. 4. 0.]\n",
      " [5. 4. 0.]\n",
      " [6. 4. 0.]\n",
      " [7. 4. 0.]\n",
      " [8. 4. 0.]\n",
      " [9. 4. 0.]\n",
      " [0. 5. 0.]\n",
      " [1. 5. 0.]\n",
      " [2. 5. 0.]\n",
      " [3. 5. 0.]\n",
      " [4. 5. 0.]\n",
      " [5. 5. 0.]\n",
      " [6. 5. 0.]\n",
      " [7. 5. 0.]\n",
      " [8. 5. 0.]\n",
      " [9. 5. 0.]\n",
      " [0. 6. 0.]\n",
      " [1. 6. 0.]\n",
      " [2. 6. 0.]\n",
      " [3. 6. 0.]\n",
      " [4. 6. 0.]\n",
      " [5. 6. 0.]\n",
      " [6. 6. 0.]\n",
      " [7. 6. 0.]\n",
      " [8. 6. 0.]\n",
      " [9. 6. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(10,9,0)\n",
    "objp = np.zeros((number_of_internal_corners_x * number_of_internal_corners_y,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:number_of_internal_corners_x,0:number_of_internal_corners_y].T.reshape(-1,2)\n",
    "print(objp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get image points\n",
    "This function is used to get the image points of the chessboard. So the results can be reused during intrinsic calibration and extrinsic calibration.\n",
    "\n",
    "Parameters:  \n",
    "    None  \n",
    "Return:  \n",
    "    rets: array of boolean values, True if the chessboard is found, False otherwise shape (number of cameras, number of frames)  \n",
    "    objpoints: array of image points shape (number of frames, number of cameras, number_of_internal_corners_x * number_of_internal_corners_y, 2)  \n",
    "    shape: tuple of the shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_points():\n",
    "    imgpoints = [] # 2D points in image plane\n",
    "    objpoints = [] # 3D points in world coordinate system\n",
    "    rets = [] # boolean values\n",
    "    \n",
    "    images = glob.glob('screen_shots/*.png')\n",
    "    \n",
    "    shape = (0,0)\n",
    "    \n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        frame1, frame2, frame3, frame4, frame5, frame6 = frame_slicing.slicing_frame(gray)\n",
    "        frames = [frame1, frame2, frame3, frame4, frame5]\n",
    "        \n",
    "        frame_imgpoints = np.zeros((len(frames), number_of_internal_corners_x * number_of_internal_corners_y, 2))\n",
    "        frame_objpoints = np.zeros((len(frames), number_of_internal_corners_x * number_of_internal_corners_y, 3))\n",
    "        frame_rets = np.zeros(len(frames), dtype=bool) + True\n",
    "        \n",
    "        for i in range(len(frames)):\n",
    "            frame = frames[i]\n",
    "            shape = frame.shape\n",
    "            \n",
    "            ret, corners = cv2.findChessboardCorners(frame, (number_of_internal_corners_x,number_of_internal_corners_y), None)\n",
    "            \n",
    "            if ret == True:\n",
    "                corners2 = cv2.cornerSubPix(frame, corners, (11,11), (-1,-1), criteria=criteria)\n",
    "                frame_objpoints[i, :, :] = objp\n",
    "                frame_imgpoints[i, :, :] = corners2[:, 0, :]\n",
    "                \n",
    "                cv2.drawChessboardCorners(frame, (number_of_internal_corners_x,number_of_internal_corners_y), corners2, ret)\n",
    "                \n",
    "            else:\n",
    "                frame_rets[i] = False\n",
    "                \n",
    "        imgpoints.append(frame_imgpoints)\n",
    "        objpoints.append(frame_objpoints)\n",
    "        rets.append(frame_rets)\n",
    "        \n",
    "        frame_with_corners = frame_concatent.concatent_frame(frames)\n",
    "        cv2.imwrite(f'chessboard_points/{fname.split(\"/\")[-1]}', frame_with_corners)\n",
    "        \n",
    "    imgpoints = np.array(imgpoints)\n",
    "    objpoints = np.array(objpoints)\n",
    "    rets = np.array(rets)\n",
    "        \n",
    "    return rets, imgpoints, objpoints, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic_calibration(rets, imgpoints, objpoints, shape):\n",
    "    mtxs = []\n",
    "    dists = []\n",
    "    \n",
    "    for camera_name in cameras:\n",
    "        imgpoints_camera = imgpoints[:, cameras.index(camera_name), :, :]\n",
    "        objpoints_camera = objpoints[:, cameras.index(camera_name), :, :]\n",
    "        rets_camera = rets[:, cameras.index(camera_name)]\n",
    "        imgpoints_camera = imgpoints_camera[rets_camera, :, :]\n",
    "        objpoints_camera = objpoints_camera[rets_camera, :, :]\n",
    "        \n",
    "        number_of_images = len(rets_camera)\n",
    "        number_of_success_images = np.sum(rets_camera.astype(int))\n",
    "        \n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints_camera, imgpoints_camera, shape[::-1], None, None)\n",
    "        \n",
    "        with open(f'results/intrinsic_{camera_name}.json', 'w') as f:\n",
    "            json.dump({'mtx': mtx.tolist(), 'dist': dist.tolist()}, f)\n",
    "        \n",
    "        print(f'{camera_name} has {number_of_success_images}/{number_of_images} successful images')\n",
    "        \n",
    "        mean_error = 0\n",
    "        for i in range(len(objpoints)):\n",
    "            imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "            error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "            mean_error += error\n",
    "        mean_error = mean_error / len(objpoints)\n",
    "        print(f'{camera_name} has mean error: {mean_error}')\n",
    "        \n",
    "        mtxs.append(mtx[0])\n",
    "        dists.append(dist[0])\n",
    "        \n",
    "    mtxs = np.array(mtxs)\n",
    "    dists = np.array(dists)\n",
    "    \n",
    "    return mtxs, dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrinsic calibration\n",
    "\n",
    "### Transformation Matrix\n",
    "\n",
    "$$ H = \\begin{bmatrix} R & t \\\\ 0 & 1 \\end{bmatrix} \n",
    "    = \\begin{bmatrix} r_{11} & r_{12} & r_{13} & t_x \\\\ r_{21} & r_{22} & r_{23} & t_y \\\\ r_{31} & r_{32} & r_{33} & t_z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrinsic_calibration(mtxs, dists):\n",
    "\n",
    "    images = glob.glob('screen_shots/*.png')\n",
    "\n",
    "    effective_chessboard_count = 0\n",
    "    total_chessboard_count = 0\n",
    "    \n",
    "    transformation_matrices = []\n",
    "\n",
    "    for image in images:\n",
    "        cameras_ret = True\n",
    "        if len(image.split('/')[1].split('_')) != 1:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        frame1, frame2, frame3, frame4, frame5, frame6 = frame_slicing.slicing_frame(gray)\n",
    "        frames = [frame1, frame2, frame3, frame4, frame5]\n",
    "        \n",
    "        transformation_matrix_temp = np.zeros((len(cameras), 4, 4))\n",
    "        \n",
    "        for camera in cameras:\n",
    "            frame = frames[cameras.index(camera)]\n",
    "            ret, corners = cv2.findChessboardCorners(frame, (number_of_internal_corners_x,number_of_internal_corners_y), None)\n",
    "        \n",
    "            if ret == True:\n",
    "                corners = cv2.cornerSubPix(frame, corners, (11,11), (-1,-1), criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "                ret, rvec, tvec = cv2.solvePnP(objp, corners, mtxs[cameras.index(camera)], dists[cameras.index(camera)])\n",
    "                \n",
    "                imgpts, _ = cv2.projectPoints(objp, rvec, tvec, mtxs[cameras.index(camera)], dists[cameras.index(camera)])\n",
    "                frame = draw(frame,corners,imgpts)\n",
    "                cv2.imwrite(f'reprojection/img_f{image.split(\"/\")[1]}_{camera}.png', frame)\n",
    "                \n",
    "                R, _ = cv2.Rodrigues(rvec)\n",
    "                # The rvec and tvec are the object points in the camera coordinate system\n",
    "                transformation_matrix_temp[cameras.index(camera), :3, :3] = R\n",
    "                transformation_matrix_temp[cameras.index(camera), :3, 3] = tvec.T[0]\n",
    "                transformation_matrix_temp[cameras.index(camera), 3, 3] = 1\n",
    "                # Find the inverse matrix so we can find the object points of the camera relative to the chessboard\n",
    "                transformation_matrix_temp[cameras.index(camera), :, :] = np.linalg.inv(transformation_matrix_temp[cameras.index(camera), :, :])\n",
    "            else:\n",
    "                cameras_ret = False\n",
    "            \n",
    "        if cameras_ret:\n",
    "            transformation_matrices.append(transformation_matrix_temp)\n",
    "            effective_chessboard_count += 1\n",
    "        \n",
    "        total_chessboard_count += 1\n",
    "        \n",
    "    print(f'Effective Chessboard: {effective_chessboard_count}/{total_chessboard_count}')\n",
    "    transformation_matrices = np.array(transformation_matrices)\n",
    "    # The transformation matrices are the transformation matrix from the chessboard to the camera\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_origin(transformation_matrices):\n",
    "    for i in range(transformation_matrices.shape[0]):\n",
    "        chess_board_transformation_matrix = np.linalg.inv(transformation_matrices[i, 2, :, :])\n",
    "        transformation_matrices[i, 0, :, :] = transformation_matrices[i, 0, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 1, :, :] = transformation_matrices[i, 1, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 3, :, :] = transformation_matrices[i, 3, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 4, :, :] = transformation_matrices[i, 4, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 2, :, :] = np.zeros((4, 4))\n",
    "        transformation_matrices[i, 2, 3, 3] = 1\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(transformation_matrices):\n",
    "    # TODO: Remove outliers\n",
    "    transformation_matrices = transformation_matrices[0, :, :, :]\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project arrows into the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "\n",
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel().astype(\"int32\"))\n",
    "    imgpts = imgpts.astype(\"int32\")\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img\n",
    "\n",
    "def visualize(transformation_matrices):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(2, 3, 1, projection='3d')\n",
    "    for i in range(len(transformation_matrices)):\n",
    "        orientation = np.array([1, 0, 0]) @ transformation_matrices[i, :3, :3]\n",
    "        ax.quiver(transformation_matrices[i, 3, 0], transformation_matrices[i, 3, 1], transformation_matrices[i, 3, 2], orientation[0], orientation[1], orientation[2], color = 'red', length=0.1)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets, imgpoints, objpoints, shape = get_image_points()\n",
    "mtxs, dists = intrinsic_calibration(rets, imgpoints, objpoints, shape)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 50))\n",
    "\n",
    "for i in range(5):\n",
    "    images = os.listdir('chessboard_points')\n",
    "    random_index = random.randint(0, len(images) - 1)\n",
    "    image = cv2.imread(f'screen_shots/{images[random_index]}')\n",
    "    ax = fig.add_subplot(5, 2, i * 2 + 1)\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f'Before calibration {i}')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    frame1, frame2, frame3, frame4, frame5, frame6 = frame_slicing.slicing_frame(image)\n",
    "    frames = [frame1, frame2, frame3, frame4, frame5]\n",
    "    \n",
    "    for j in range(len(frames)):\n",
    "        frame = frames[j]        \n",
    "        h,  w = frame.shape[:2]\n",
    "        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtxs[j], dists[j], (w,h), 1, (w,h))\n",
    "        dst = cv2.undistort(frame, mtxs[j], dists[j], None, newcameramtx)\n",
    "        x, y, w, h = roi\n",
    "        frames[j] = dst[y:y+h, x:x+w]\n",
    "        \n",
    "    images_after_calibration = frame_concatent.concatent_frame(frames)\n",
    "    ax = fig.add_subplot(5, 2, i * 2 + 2)\n",
    "    ax.imshow(images_after_calibration)\n",
    "    ax.set_title(f'After calibration {i}')\n",
    "    ax.axis('off')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_matrices = extrinsic_calibration(mtxs, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_matrices = set_origin(transformation_matrices)\n",
    "transformation_matrices = remove_outliers(transformation_matrices)\n",
    "with open(f'results/extrinsic.json', 'w') as f:\n",
    "    for i in range(transformation_matrices.shape[0]):\n",
    "        json.dump(transformation_matrices[i].tolist(), f)\n",
    "        f.write('\\n')\n",
    "fig = visualize(transformation_matrices)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "underwater_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
