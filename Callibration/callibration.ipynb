{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import utils.frame_slicing as frame_slicing\n",
    "\n",
    "number_of_squares_x = 11\n",
    "number_of_internal_corners_x = number_of_squares_x - 1\n",
    "number_of_squares_y = 8\n",
    "number_of_internal_corners_y = number_of_squares_y - 1\n",
    "square_size = 0.023 # in meters\n",
    "cameras = ['cam2', 'cam3', 'wide', 'cam0', 'cam1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(10,9,0)\n",
    "objp = np.zeros((number_of_internal_corners_x * number_of_internal_corners_y,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:number_of_internal_corners_x,0:number_of_internal_corners_y].T.reshape(-1,2)\n",
    "objp = objp * square_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic_calibration(camera_name):\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    images = glob.glob('screen_shots/*.png')\n",
    "\n",
    "    shape = (0,0)\n",
    "\n",
    "    effective_chessboard_count = 0\n",
    "    total_chessboard_count = 0\n",
    "\n",
    "    for fname in images:\n",
    "        fname_parts = fname.split('/')[1].split('_')\n",
    "        if fname_parts[0] != camera_name:\n",
    "            continue\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        shape = gray.shape\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (number_of_internal_corners_x,number_of_internal_corners_y), None)\n",
    "        # Corners: numpy array of shape (number_of_internal_corners, 1, 2)\n",
    "        \n",
    "        if ret == True:\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            effective_chessboard_count += 1\n",
    "            \n",
    "        total_chessboard_count += 1\n",
    "\n",
    "    if (effective_chessboard_count < 10):\n",
    "        raise ValueError(f'Not enough effective chessboard found: {effective_chessboard_count}/{total_chessboard_count}')\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, shape[::-1], None, None)\n",
    "    \n",
    "    print(f'{camera_name} Effective Chessboard: {effective_chessboard_count}/{total_chessboard_count}')\n",
    "\n",
    "    with open(f'results/intrinsic_{camera_name}.json', 'w') as f:\n",
    "        json.dump({'mtx': mtx.tolist(), 'dist': dist.tolist()}, f)\n",
    "        \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrinsic_calibration(mtxs, dists):\n",
    "\n",
    "    images = glob.glob('screen_shots/*.png')\n",
    "\n",
    "    effective_chessboard_count = 0\n",
    "    total_chessboard_count = 0\n",
    "    \n",
    "    transformation_matrices = {}\n",
    "\n",
    "    for image in images:\n",
    "        cameras_ret = True\n",
    "        if len(image.split('/')[1].split('_')) != 1:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        frame1, frame2, frame3, frame4, frame5, frame6 = frame_slicing.slicing_frame(gray)\n",
    "        frames = [frame1, frame2, frame3, frame4, frame5]\n",
    "        \n",
    "        transformation_matrix_temp = np.zeros((len(cameras), 4, 4))\n",
    "        \n",
    "        for camera in cameras:\n",
    "            ret, corners = cv2.findChessboardCorners(frames[cameras.index(camera)], (number_of_internal_corners_x,number_of_internal_corners_y), None)\n",
    "        \n",
    "            if ret == True:\n",
    "                corners = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "                ret, rvec, tvec = cv2.solvePnP(objp, corners, mtxs[cameras.index(camera)], dists[cameras.index(camera)])\n",
    "                print(rvec)\n",
    "                print(tvec)\n",
    "                # The rvec and tvec are the object points in the camera coordinate system\n",
    "                transformation_matrix_temp[cameras.index(camera), :, :] = np.concatenate((rvec, tvec), axis=1)\n",
    "                transformation_matrix_temp[cameras.index(camera), 3, 3] = 1\n",
    "                # Find the inverse matrix so we can find the object points of the camera relative to the chessboard\n",
    "                transformation_matrix_temp[cameras.index(camera), :, :] = np.linalg.inv(transformation_matrix_temp[cameras.index(camera), :, :])\n",
    "            else:\n",
    "                cameras_ret = False\n",
    "            \n",
    "        if cameras_ret:\n",
    "            transformation_matrices.append(transformation_matrix_temp)\n",
    "            effective_chessboard_count += 1\n",
    "        \n",
    "        total_chessboard_count += 1\n",
    "        \n",
    "    print(f'Effective Chessboard: {effective_chessboard_count}/{total_chessboard_count}')\n",
    "    transformation_matrices = np.array(transformation_matrices)\n",
    "    # The transformation matrices are the transformation matrix from the chessboard to the camera\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Matrix\n",
    "\n",
    "$$ H = \\begin{bmatrix} R & t \\\\ 0 & 1 \\end{bmatrix} \n",
    "    = \\begin{bmatrix} r_{11} & r_{12} & r_{13} & t_x \\\\ r_{21} & r_{22} & r_{23} & t_y \\\\ r_{31} & r_{32} & r_{33} & t_z \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_origin(transformation_matrices):\n",
    "    for i in range(transformation_matrices.shape[0]):\n",
    "        chess_board_transformation_matrix = np.linalg.inv(transformation_matrices[i, 2, :, :])\n",
    "        transformation_matrices[i, 2, :, :] = np.zeros((4, 4))\n",
    "        transformation_matrices[i, 2, 3, 3] = 1\n",
    "        transformation_matrices[i, 0, :, :] = transformation_matrices[i, 0, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 1, :, :] = transformation_matrices[i, 1, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 3, :, :] = transformation_matrices[i, 3, :, :] @ chess_board_transformation_matrix\n",
    "        transformation_matrices[i, 2, :, :] = transformation_matrices[i, 2, :, :] @ chess_board_transformation_matrix\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(transformation_matrices):\n",
    "    # TODO: Remove outliers\n",
    "    transformation_matrices_mean = np.mean(transformation_matrices, axis=0)\n",
    "    return transformation_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(transformation_matrices):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(2, 3, 1, projection='3d')\n",
    "    for i in range(len(transformation_matrices)):\n",
    "        orientation = np.array([1, 0, 0]) @ transformation_matrices[i, :3, :3]\n",
    "        ax.quiver(transformation_matrices[i, 3, 0], transformation_matrices[i, 3, 1], transformation_matrices[i, 3, 2], orientation[0], orientation[1], orientation[2], color = 'red', length=0.1)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = glob.glob('screen_shots/*.png')\n",
    "\n",
    "# for image in images:\n",
    "#     image_name = image.split('/')[1]\n",
    "#     img = cv2.imread(image)\n",
    "#     frame1, frame2, frame3, frame4, frame5, frame6 = frame_slicing.slicing_frame(img)\n",
    "#     cv2.imwrite(f\"screen_shots/cam2_{image_name}\", frame1)\n",
    "#     cv2.imwrite(f\"screen_shots/cam3_{image_name}\", frame2)\n",
    "#     cv2.imwrite(f\"screen_shots/wide_{image_name}\", frame3)\n",
    "#     cv2.imwrite(f\"screen_shots/cam0_{image_name}\", frame4)\n",
    "#     cv2.imwrite(f\"screen_shots/cam1_{image_name}\", frame5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam2 Effective Chessboard: 29/48\n",
      "cam3 Effective Chessboard: 34/48\n",
      "wide Effective Chessboard: 46/48\n",
      "cam0 Effective Chessboard: 28/48\n",
      "cam1 Effective Chessboard: 23/48\n"
     ]
    }
   ],
   "source": [
    "mtxs = np.zeros((len(cameras), 3, 3))\n",
    "dists = np.zeros((len(cameras), 5))\n",
    "\n",
    "for camera in cameras:\n",
    "    mtx_cam, dist_cam = intrinsic_calibration(camera)\n",
    "    mtxs[cameras.index(camera), :, :] = mtx_cam[0]\n",
    "    dists[cameras.index(camera), :] = dist_cam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.86188075e-15]\n",
      " [-9.60336792e-16]\n",
      " [ 1.98946128e-16]]\n",
      "[[-1.66460219e-17]\n",
      " [ 1.31155237e-15]\n",
      " [ 1.65781171e-16]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,2) into shape (4,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformation_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mextrinsic_calibration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmtxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdists\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mextrinsic_calibration\u001b[0;34m(mtxs, dists)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(tvec)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# The rvec and tvec are the object points in the camera coordinate system\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtransformation_matrix_temp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcameras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((rvec, tvec), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m transformation_matrix_temp[cameras\u001b[38;5;241m.\u001b[39mindex(camera), \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Find the inverse matrix so we can find the object points of the camera relative to the chessboard\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,2) into shape (4,4)"
     ]
    }
   ],
   "source": [
    "transformation_matrices = extrinsic_calibration(mtxs, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_matrices = set_origin(transformation_matrices)\n",
    "transformation_matrices = remove_outliers(transformation_matrices)\n",
    "with open(f'results/extrinsic.json', 'w') as f:\n",
    "    json.dump(transformation_matrices, f)\n",
    "fig = visualize(transformation_matrices)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "underwater_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
